Automatic Throughput and Critical Path Analysis of x86 and ARM Assembly Kernels	"Jan Laukemann, Julian Hammer, Georg Hager and Gerhard Wellein"	"Useful models of loop kernel runtimes on out-of-order architectures require an analysis of the the in-core performance behavior of instructions and their dependencies. While an instruction throughput prediction sets a lower bound to the kernel runtime, the critical path defines an upper bound. Such predictions are an essential part of analytic (i.e., white-box) performance models like the Roofline and ECM model. They enable a better understanding of the performance-relevant interactions between hardware architecture and loop code.<br/><br/>The Open Source Architecture Code Analyzer (OSACA) is a static analysis tool for predicting the execution time of sequential loops. It previously supported only x86 (Intel and AMD) architectures and simple, optimistic full-throughput execution. We have heavily extended OSACA to support ARM instructions and critical path prediction including the detection of loop-carried dependencies, which turns it into a versatile cross-architecture modeling tool. We show runtime predictions for code on Intel Cascade Lake, AMD Zen, and Marvell Vulcan micro-architectures based on machine models from available documentation and semi-automatic benchmarking. The predictions are compared with actual measurements."
An Instruction Roofline Model for GPUs	Nan Ding and Samuel Williams	"The Roofline performance model provides an intuitive approach to identify performance bottlenecks and guide performance optimization. However, the classic FLOP-centric is inappropriate for the emerging applications that perform more integer operations than floating-point operations. In this paper, we propose an Instruction Roofline Model on NVIDIA GPUs. The Instruction Roofline incorporates instructions and memory transactions across all memory hierarchies together and provides more performance insights than the FLOP-oriented Roofline Model, i.e., instruction throughput, stride memory access patterns, bank conflicts, and thread predication. We use our Instruction Roofline methodology to analyze five proxy applications: HPGMG from AMReX, BatchSW from merAligner, Matrix Transpose benchmarks, cudaTensorCoreGemm, and cuBLAS. We demonstrate the ability of our methodology to understand various aspects of performance and performance bottlenecks on NVIDIA GPUs and motivate code optimizations."
Exploiting Hardware-Accelerated Ray Tracing for Monte Carlo Particle Transport with OpenMC	Justin Salmon and Simon McIntosh-Smith	"OpenMC is a CPU-based Monte Carlo particle transport simulation code recently developed in the Computa- tional Reactor Physics Group at MIT, and which is currently being evaluated by the UK Atomic Energy Authority for use on the ITER fusion reactor project. In this paper we present a novel port of OpenMC to run on the new ray tracing (RT) cores in NVIDIA’s latest Turing GPUs. We show here that the OpenMC GPU port yields up to 9.8x speedup on a single node over a 16-core CPU using the native constructive solid geometry, and up to 13x speedup using approximate triangle mesh geometry. Furthermore, since the expensive 3D geometric operations re- quired during particle transport simulation can be formulated as a ray tracing problem, there is an opportunity to gain even higher performance on triangle meshes by exploiting the RT cores in Turing GPUs to enable hardware-accelerated ray tracing. Extending the GPU port to support RT core acceleration yields between 2x and 20x additional speedup. We note that geometric model complexity has a significant impact on performance, with RT core acceleration yielding comparatively greater speedups as complexity increases. To the best of our knowledge, this is the first work showing that exploitation of RT cores for scientific workloads is possible. We finish by drawing conclusions about RT cores in terms of wider applicability, limitations and performance portability."
Enhancing Monte Carlo proxy applications on GPUs	"Forrest Shriver, Seyong Lee, Steven Hamilton, Justin Watson and Jeffrey Vetter"	"In Monte Carlo neutron transport simulations, a computational routine commonly known as the ""cross-section lookup"" has been identified as being the most computationally expensive part of these applications. A tool which is commonly used as a proxy application for these routines, named ""XSBench"", was created to simulate popular algorithms used in these routines on CPUs. Currently, however, as GPU-based HPC resources have become more widely available, there has been significant interest and efforts invested in moving these traditionally CPU-based simulations to GPUs. Unfortunately, the algorithms commonly used in the cross-section lookup routine were originally devised and developed for CPU-based platforms, and have seen limited study on GPUs to date. Additionally, platforms such as XSBench implement approximations which may have a negligible effect on CPUs, but may be quite impactful to performance on GPUs given the more resource-limited nature of the latter. As a result, we have created VEXS, a new tool for modeling the cross-section lookup routine which removes or at least reduces the approximations made by XSBench in order to provide a more realistic prediction of algorithm performance on GPUs. In this paper, we detail our efforts to remove and reduce these approximations, show the resulting improvement in performance prediction in comparison to a reference production code, Shift, and provide some basic profiling analysis of the resulting application."
Comparing Managed Memory and UVM with and without Prefetching on NVIDIA Volta GPUs	"Rahulkumar Gayatri, Kevin Gott and Jack Deslippe"	"One of the major differences in many-core versus multicore architectures is the presence of two different memory spaces: a host space and a device space. In the case of NVIDIA GPUs, the device is supplied with data from the host via one of the multiple memory management API calls provided by the CUDA framework, such as CudaMallocManaged and CudaMemCpy. Modern systems, such as the Summit supercomputer, have the capability to avoid the use of CUDA calls for memory management and access the same data on GPU and CPU. This is done via the Address Translation Services (ATS) technology that gives a unified virtual address space for data allocated with malloc and new if there is an NVLink connection between the two memory spaces. In this paper, we perform a deep analysis of the performance achieved when using two types of unified virtual memory addressing: UVM and managed memory."
Testing the Limits of Tapered Fat Tree Networks	"Philip A. Taffet, Sanil Rao, Edgar A. León and Ian Karlin"	"HPC system procurement with a fixed budget is an optimization problem with many trade-offs. In particular, the choice of an interconnection network for a system is a major choice, since communication performance is important to overall application performance and network makes up a substantial fraction of a supercomputer’s overall price. It is necessary to understand how sensitive representative jobs are to various aspects of network performance to procure the right network. Previous studies used mostly communication-only motifs or simulation; in this study, we use dedicated time on a cluster at Lawrence Livermore National Lab to measure the performance of application running in various controlled environments. We vary background congestion, mapping and placement, and observe the impact on overall application performance. Overall, we find that a 2:1 tapered fat tree provides sufficiently robust communication performance for a representative mix of applications while generating meaningful cost savings relative to a full bisection bandwidth fat tree. Furthermore, our results advise against further tapering, as the resulting performance degradation would exceed cost savings. However, application-specific mappings and topology-aware schedulers may reduce global bandwidth needs, providing room for additional network tapering."
Validation of gem5 for x86 Platforms	Ayaz Akram and Lina Sawalha	"gem5 has been extensively used in computer architecture simulations and in the evaluation of new architectures for HPC (high performance computing) systems. Previous work has validated gem5 against ARM platforms. However, gem5 still shows high inaccuracy when modeling Intel’s x86 based processors. In this work, we focus on the simulation of a single node high performance system and study the sources of inaccuracies of gem5. Then we validate gem5 simulator against an Intel processor, Core-i7 (Haswell microarchitecture). We configured gem5 as close as possible to match Core-i7 Haswell microarchitecture configurations and made changes to the simulator to add some features, modified existing code, and tuned built-in configurations. As a result, we validated the simulator by fixing many sources of errors to match real hardware results with less than 6% mean error rate for different control, memory, dependency and execution microbenchmarks."
Low-overhead monitoring for detecting application runtime anomalies	"Sudheer Chunduri, Elise Jennings, Kevin Harms, Christopher Knight and Scott Parker"	"Shared network topologies, such as dragonfly, subject applications to unavoidable inter-job interference arising from congestion on shared network links. Quantifying the impact of congestion is essential for effectively assessing and comparing the application runtimes. We use network performance counter-based metrics for this quantification. We claim and demonstrate that by using a local view of congestion captured through the counters monitored during a given application run, we can accurately determine the run conditions and thereby estimate the impact on the application’s performance. We construct a predictive model that is trained using applications with distinctive communication characteristics run under production system conditions."
CUDA Flux: A Lightweight Instruction Profiler for CUDA Applications	Lorenz Braun and Holger Fröning	"GPUs are powerful, massively parallel processors, which require a vast amount of thread parallelism to keep their thousands of execution units busy, and to tolerate latency when accessing its high-throughput memory system. Understanding the behavior of massively threaded GPU programs can be difficult, even though recent GPUs provide an abundance of hardware performance counters, which collect statistics about certain events. State-of-the-art are profiling tools that assist the user in such analysis, like for NVIDIA's nvprof and cupti for their GPUs. However, instrumentation based on reading hardware performance counters can be slow, in particular when the number of metrics is large. Furthermore, the results can be inaccurate as instructions are grouped to match the available set of counters.<br/><br/>In this work we introduce CUDA Flux, an alternative to profiling based on hardware performance counters. As part of CUDA compilation, code is instrumented to collect statistics about the control flow. Resulting instruction count is then calculated based on these statistics in combination with an analysis of PTX assembly. <br/><br/>In general, trade-offs in between number of instrumented threads and instrumentation overhead is possible, due to reasons including thread-dependent behavior like branch divergence.<br/><br/>Our experiments show that code instrumentation and associated data acquisition is usually faster than reading out a large amount of hardware performance counters, like being done by nvprof. Ultimately, we see code instrumentation as highly flexible, with many possibilities to trade accuracy for resource requirements, while the fundamental techniques can be preserved."
"OMB-UM: Design, Implementation, and Evaluation of CUDA Unified Memory Aware MPI Benchmarks"	"Karthik Vadambacheri Manian, Ching-Hsiang Chu, Ammar Ahmad Awan, Kawthar Shafie Khorassani, Hari Subramoni and Dhabaleswar K. Panda"	"Unified Memory (UM) has significantly simplified the task of programming CUDA applications. With UM, the CUDA driver is responsible for managing the data movement between CPU and GPU and the programmer can focus on the actual designs. However, the performance of Unified Memory codes has not been on par with explicit device buffer based code. To this end, the latest NVIDIA Pascal and Volta GPUs with hardware support such as fine-grained page faults offer the best of both worlds, i.e., high-productivity and high-performance. However, these enhancements in the newer generation GPU architectures need to be evaluated in a different manner, especially in the context of MPI+CUDA applications. In this paper, we extend the widely used MPI benchmark — OSU Micro-benchmarks (OMB) to support Unified Memory or Managed Memory based MPI benchmarks. The current version of OMB cannot effectively characterize UM-Aware MPI design because CUDA driver movements are not captured appropriately with standardized Host and Device buffer based benchmarks. To address this key challenge, we propose new designs for the OMB suite and extend point to point and collective benchmarks that exploit sender and receiver side CUDA kernels to emulate the effective location of the UM buffer on Host and Device. The new benchmarks allow the users to better understand the performance of codes with UM buffers through user-selectable knobs that enable or disable sender and receiver side CUDA kernels. In addition to the design and implementation, we provide a comprehensive performance evaluation of the new UM benchmarks in the OMB-UM suite on a wide variety of systems and MPI libraries. From these evaluations we also provide valuable insights on the performance of various MPI libraries on UM buffers which can lead to further improvement in the performance of UM in CUDA-Aware MPI libraries."
Fine-Grained Analysis of Communication Similarity between Real and Proxy Applications	"Omar Aaziz, Courtenay Vaughan, Jonathan Cook, Jeanine Cook, Jeffrey Kuehn and David Richards"	"In this work we investigate the dynamic communication behavior of parent and proxy applications, and investigate whether or not the dynamic communication behavior of the proxy matches that of its respective parent application. The idea of proxy applications is that they should match their parent well, and should exercise the hardware and perform similarly, so that from them lessons can be learned about how the HPC system and the application can best be utilized. We show here that some proxy/parent pairs do not need the extra detail of dynamic behavior analysis, while others can benefit from it, and through this we also identified a parent/proxy mismatch and improved the proxy application."
Performance Analysis of Deep Learning Workloads on Leading-edge Systems	"Yihui Ren, Shinjae Yoo and Adolfy Hoisie"	"This work examines the performance of leading-edge systems designed for machine learning computing, including the NVIDIA DGX-2, Amazon Web Services (AWS) P3, IBM Power System Accelerated Compute Server AC922, and a consumer-grade Exxact TensorEX TS4 GPU server. Representative deep learning workloads from the fields of computer vision and natural language processing are the focus of the analysis. Performance analysis is performed along with a number of important dimensions. Performance of the communication interconnects and large and high-throughput deep learning models are considered. Different potential use models for the systems as standalone and in the cloud also are examined. The effect of various optimization of the deep learning models and system configurations is included in the analysis."

